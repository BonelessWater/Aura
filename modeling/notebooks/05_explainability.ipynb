{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Act 4: The Trust (Part 1)\n",
    "\n",
    "## Explainability: Why Did the Model Flag This Patient?\n",
    "\n",
    "> \"A physician won't act on a black box. They need to know: *which lab values drove this prediction?* SHAP gives us that — for every single patient.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **ESR and CRP z-scores are the #1 drivers** globally — aligns with clinical intuition\n",
    "2. **SHAP waterfall plots** explain each individual prediction in plain terms\n",
    "3. **Systemic cluster patients**: ANA, autoantibody count, and inflammatory burden drive predictions\n",
    "4. **GI cluster patients**: CRP elevation and demographics drive predictions (fewer specific markers)\n",
    "5. **Natural language explanations** translate SHAP values into clinician-readable summaries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path('../src').resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "Path('../outputs/figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loaders import load_modeling_data\n",
    "from data.preprocessing import preprocess_for_modeling, create_splits, prepare_features\n",
    "from data.feature_engineering import engineer_all_features\n",
    "from models.dual_scorer import train_dual_scorer\n",
    "\n",
    "df = load_modeling_data()\n",
    "df = preprocess_for_modeling(df, priority_only=True)\n",
    "df = engineer_all_features(df)\n",
    "\n",
    "train, val, test = create_splits(df, random_state=RANDOM_STATE)\n",
    "\n",
    "feature_groups = ['demographics', 'cbc', 'inflammatory', 'zscore', 'missing']\n",
    "X_train, features = prepare_features(train, feature_groups)\n",
    "X_val, _ = prepare_features(val, feature_groups)\n",
    "X_test, _ = prepare_features(test, feature_groups)\n",
    "\n",
    "scorer, results = train_dual_scorer(\n",
    "    X_train, train['diagnosis_cluster'],\n",
    "    X_val=X_val, y_val=val['diagnosis_cluster'],\n",
    "    X_test=X_test, y_test=test['diagnosis_cluster'],\n",
    ")\n",
    "\n",
    "print(f'Model trained. Test AUC: {results[\"test\"][\"auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Global Feature Importance via SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) assigns each feature a contribution score for each prediction. Unlike model coefficients, SHAP handles non-linear interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability.shap_analysis import compute_shap_for_dual_scorer, get_top_features\n",
    "\n",
    "# Use a sample for speed\n",
    "sample_size = min(500, len(X_test))\n",
    "X_sample = X_test.iloc[:sample_size].copy()\n",
    "\n",
    "print(f'Computing SHAP values for {sample_size} test patients...')\n",
    "shap_values = compute_shap_for_dual_scorer(scorer, X_sample)\n",
    "print('Done!')\n",
    "\n",
    "top_features = get_top_features(shap_values, n=15)\n",
    "print('\\nTop 15 features by mean |SHAP|:')\n",
    "print(top_features.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of global importance\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "top_n = min(15, len(top_features))\n",
    "ax.barh(\n",
    "    range(top_n),\n",
    "    top_features['mean_abs_shap'].values[:top_n],\n",
    "    color='steelblue', alpha=0.85\n",
    ")\n",
    "ax.set_yticks(range(top_n))\n",
    "ax.set_yticklabels(top_features['feature'].values[:top_n])\n",
    "ax.set_xlabel('Mean |SHAP Value|')\n",
    "ax.set_title('Global Feature Importance (SHAP)\\nMean absolute contribution across test patients', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/05_shap_global_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. SHAP Summary Plot: Feature Impact Direction\n",
    "\n",
    "The summary plot shows *both* importance and direction — positive SHAP means the feature pushes toward autoimmune prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP summary plot for systemic class (class index 1 in most configs)\n",
    "categories = scorer.categories\n",
    "systemic_idx = categories.index('systemic') if 'systemic' in categories else 1\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "if len(shap_values.shape) == 3:\n",
    "    # Multi-class: select systemic class\n",
    "    shap.summary_plot(\n",
    "        shap_values[:, :, systemic_idx],\n",
    "        X_sample,\n",
    "        max_display=15,\n",
    "        show=False,\n",
    "        plot_type='dot'\n",
    "    )\n",
    "    plt.title('SHAP Summary: Systemic Autoimmune Class', fontweight='bold')\n",
    "else:\n",
    "    shap.summary_plot(shap_values, X_sample, max_display=15, show=False, plot_type='dot')\n",
    "    plt.title('SHAP Summary: All Classes', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/05_shap_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Per-Class SHAP: What Drives Each Cluster?\n",
    "\n",
    "Different features dominate different clusters — this aligns with known clinical biology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(shap_values.shape) == 3:\n",
    "    n_classes = shap_values.shape[2]\n",
    "    fig, axes = plt.subplots(1, min(n_classes, 4), figsize=(20, 6))\n",
    "\n",
    "    if n_classes == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for cls_idx, (ax, cls_name) in enumerate(zip(axes, categories[:4])):\n",
    "        vals = np.abs(shap_values.values[:, :, cls_idx]).mean(axis=0)\n",
    "        feat_names = shap_values.feature_names\n",
    "        top_idx = np.argsort(vals)[::-1][:10]\n",
    "\n",
    "        cluster_colors = {'healthy': '#2ecc71', 'systemic': '#e74c3c',\n",
    "                          'gastrointestinal': '#3498db', 'endocrine': '#9b59b6'}\n",
    "        color = cluster_colors.get(cls_name, 'gray')\n",
    "\n",
    "        ax.barh(range(10), vals[top_idx][::-1], color=color, alpha=0.8)\n",
    "        ax.set_yticks(range(10))\n",
    "        ax.set_yticklabels([feat_names[i] for i in top_idx[::-1]], fontsize=9)\n",
    "        ax.set_xlabel('Mean |SHAP|')\n",
    "        ax.set_title(f'{cls_name.upper()}', fontweight='bold', color=color)\n",
    "\n",
    "    plt.suptitle('Top Features per Disease Cluster (SHAP)', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/figures/05_shap_per_class.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Per-class SHAP requires multi-class model output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Individual Patient Explanation: Waterfall Plot\n",
    "\n",
    "For each patient, we can trace exactly which lab values pushed the prediction — and by how much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a high-confidence systemic patient in our sample\n",
    "predictions = scorer.predict(X_sample)\n",
    "test_sample = test.iloc[:sample_size].copy()\n",
    "test_sample['pred_category'] = [p.category for p in predictions]\n",
    "test_sample['pred_confidence'] = [p.category_confidence for p in predictions]\n",
    "\n",
    "# Case: High-confidence systemic TP\n",
    "systemic_tp = test_sample[\n",
    "    (test_sample['diagnosis_cluster'] == 'systemic') &\n",
    "    (test_sample['pred_category'] == 'systemic') &\n",
    "    (test_sample['pred_confidence'] > 0.85)\n",
    "]\n",
    "\n",
    "if len(systemic_tp) > 0:\n",
    "    sample_idx = list(test_sample.index).index(systemic_tp.index[0])\n",
    "    pt = systemic_tp.iloc[0]\n",
    "    print(f'Case: {pt[\"patient_id\"]} | {pt[\"age\"]:.0f}yo {pt[\"sex\"]} | {pt[\"diagnosis_cluster\"]} | Predicted: {pt[\"pred_category\"]} ({pt[\"pred_confidence\"]:.1%})')\n",
    "else:\n",
    "    sample_idx = 0\n",
    "    print('Using first sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for the selected patient\n",
    "from explainability.shap_analysis import plot_waterfall\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "if len(shap_values.shape) == 3:\n",
    "    shap.waterfall_plot(\n",
    "        shap_values[sample_idx, :, systemic_idx],\n",
    "        max_display=12,\n",
    "        show=False\n",
    "    )\n",
    "else:\n",
    "    shap.waterfall_plot(shap_values[sample_idx], max_display=12, show=False)\n",
    "\n",
    "plt.title(f'SHAP Waterfall: Individual Patient Explanation (Systemic Class)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/05_shap_waterfall.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Natural Language Explanations\n",
    "\n",
    "Physicians need words, not numbers. We translate SHAP values into clinical narratives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability.shap_analysis import get_sample_explanation\n",
    "from explainability.case_explanations import generate_explanation, format_clinical_summary, format_patient_summary\n",
    "\n",
    "# Get SHAP explanation for our sample patient\n",
    "shap_exp = get_sample_explanation(\n",
    "    shap_values,\n",
    "    sample_idx,\n",
    "    X_sample.iloc[sample_idx],\n",
    "    class_idx=systemic_idx,\n",
    "    n_features=5\n",
    ")\n",
    "\n",
    "# Generate natural language explanation\n",
    "pred = predictions[sample_idx]\n",
    "nl_exp = generate_explanation(\n",
    "    patient_id=test_sample.iloc[sample_idx].get('patient_id', f'patient_{sample_idx}'),\n",
    "    patient_features=X_sample.iloc[sample_idx],\n",
    "    shap_explanation=shap_exp,\n",
    "    prediction_result=pred.to_dict()\n",
    ")\n",
    "\n",
    "print(format_clinical_summary(nl_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patient-friendly version\n",
    "print(format_patient_summary(nl_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Three Contrasting Cases\n",
    "\n",
    "Same format, different clinical stories — demonstrating the model's ability to distinguish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_types = [\n",
    "    ('High-confidence Systemic TP', 'systemic', 'systemic', 0.85),\n",
    "    ('Healthy TN', 'healthy', 'healthy', 0.80),\n",
    "]\n",
    "\n",
    "for case_name, true_cluster, pred_cluster, conf_thresh in case_types:\n",
    "    mask = (\n",
    "        (test_sample['diagnosis_cluster'] == true_cluster) &\n",
    "        (test_sample['pred_category'] == pred_cluster) &\n",
    "        (test_sample['pred_confidence'] >= conf_thresh)\n",
    "    )\n",
    "    candidates = test_sample[mask]\n",
    "\n",
    "    if len(candidates) == 0:\n",
    "        print(f'{case_name}: No matching patients found in sample\\n')\n",
    "        continue\n",
    "\n",
    "    case_df_idx = candidates.index[0]\n",
    "    case_sample_idx = list(test_sample.index).index(case_df_idx)\n",
    "    case_row = candidates.iloc[0]\n",
    "    case_pred = predictions[case_sample_idx]\n",
    "\n",
    "    cls_idx = systemic_idx if pred_cluster == 'systemic' else 0\n",
    "\n",
    "    shap_case = get_sample_explanation(\n",
    "        shap_values, case_sample_idx,\n",
    "        X_sample.iloc[case_sample_idx],\n",
    "        class_idx=cls_idx, n_features=3\n",
    "    )\n",
    "\n",
    "    nl_case = generate_explanation(\n",
    "        patient_id=case_row.get('patient_id', f'patient_{case_sample_idx}'),\n",
    "        patient_features=X_sample.iloc[case_sample_idx],\n",
    "        shap_explanation=shap_case,\n",
    "        prediction_result=case_pred.to_dict()\n",
    "    )\n",
    "\n",
    "    print(f'=== {case_name} ===')\n",
    "    print(nl_case.clinical_narrative)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. SHAP Dependence Plot: CRP × Age Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP dependence: CRP z-score vs its SHAP contribution, colored by age\n",
    "feat_names = list(X_sample.columns)\n",
    "\n",
    "crp_zscore_col = 'crp_zscore' if 'crp_zscore' in feat_names else None\n",
    "age_col = 'age' if 'age' in feat_names else None\n",
    "\n",
    "if crp_zscore_col and len(shap_values.shape) == 3:\n",
    "    crp_idx = feat_names.index(crp_zscore_col)\n",
    "    shap_crp = shap_values.values[:, crp_idx, systemic_idx]\n",
    "    x_crp = X_sample[crp_zscore_col].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "    if age_col:\n",
    "        age_vals = X_sample[age_col].values\n",
    "        sc = ax.scatter(x_crp, shap_crp, c=age_vals, cmap='RdYlGn_r',\n",
    "                        alpha=0.6, s=20)\n",
    "        plt.colorbar(sc, ax=ax, label='Age')\n",
    "    else:\n",
    "        ax.scatter(x_crp, shap_crp, alpha=0.4, s=20)\n",
    "\n",
    "    ax.axhline(y=0, color='black', linewidth=0.8, alpha=0.5)\n",
    "    ax.axvline(x=2, color='red', linestyle='--', alpha=0.5, label='+2 SD')\n",
    "    ax.set_xlabel('CRP Z-Score')\n",
    "    ax.set_ylabel('SHAP Value (systemic class)')\n",
    "    ax.set_title('SHAP Dependence: CRP Z-Score → Systemic Risk\\n(colored by age)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/figures/05_shap_dependence_crp.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\nelse:\n",
    "    print('CRP z-score dependence plot skipped (feature not in model or wrong shape)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **ESR and CRP z-scores are the primary global drivers** — confirms clinical knowledge\n",
    "2. **Each cluster has distinct top features**: Systemic → antibody markers; GI → CRP + demographics\n",
    "3. **Individual explanations are actionable**: Physicians see which specific values to investigate\n",
    "4. **Natural language summaries** make predictions interpretable to non-technical users\n",
    "5. **SHAP is non-linear aware**: Captures interactions that logistic regression coefficients miss\n",
    "\n",
    "---\n",
    "\n",
    "*Next: 06_bias_audit.ipynb — Act 4: The Trust (Part 2)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
