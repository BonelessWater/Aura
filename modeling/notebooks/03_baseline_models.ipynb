{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Act 3: The Proof (Part 1)\n",
    "\n",
    "## Baseline Models: Establishing the Performance Floor\n",
    "\n",
    "> \"A good model starts with something simple. If logistic regression can't separate sick from healthy, more complexity won't save you. But if it can — and it can — then we've proven there's real signal.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Logistic Regression AUC ~0.87**: Strong baseline with just CBC + inflammatory markers\n",
    "2. **Z-scores add ~2-3% AUC** over raw values — normalization matters\n",
    "3. **Systemic cluster is most separable**: AUC ~0.94 in one-vs-rest\n",
    "4. **GI cluster is hardest**: Fewer unique markers, lower confidence\n",
    "5. **Interpretable coefficients**: ESR and CRP dominate — clinically sensible\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path('../src').resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "from visualization.style import apply_aura_style, PALETTE, C, CATEGORY_COLOR, CAT_COLORS\n",
    "from visualization.style import AURA_DIVERGING, AURA_SEQUENTIAL, AURA_TEAL, AURA_RDYLGN\n",
    "apply_aura_style()\n",
    "\n",
    "Path('../outputs/figures').mkdir(parents=True, exist_ok=True)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# ── Label helpers ──────────────────────────────────────────────────────────────\n",
    "LAB_LABELS = {\n",
    "    'wbc': 'WBC', 'rbc': 'RBC', 'hemoglobin': 'Hemoglobin',\n",
    "    'hematocrit': 'Hematocrit', 'platelet_count': 'Platelet Count',\n",
    "    'mcv': 'MCV', 'mch': 'MCH', 'rdw': 'RDW', 'esr': 'ESR', 'crp': 'CRP',\n",
    "    'wbc_zscore': 'WBC Z-Score', 'rbc_zscore': 'RBC Z-Score',\n",
    "    'hemoglobin_zscore': 'Hemoglobin Z-Score',\n",
    "    'esr_zscore': 'ESR Z-Score', 'inflammatory_burden': 'Inflammatory Burden',\n",
    "    'lab_abnormality_count': 'Lab Abnormality Count',\n",
    "    'sex_encoded': 'Sex', 'anemia_flag': 'Anemia Flag',\n",
    "}\n",
    "CLUSTER_LABELS = {\n",
    "    'healthy': 'Healthy', 'systemic': 'Systemic',\n",
    "    'gastrointestinal': 'Gastrointestinal', 'endocrine': 'Endocrine',\n",
    "}\n",
    "\n",
    "def clean_label(s):\n",
    "    s = str(s)\n",
    "    if s in CLUSTER_LABELS:\n",
    "        return CLUSTER_LABELS[s]\n",
    "    if s in LAB_LABELS:\n",
    "        return LAB_LABELS[s]\n",
    "    return s.replace('_', ' ').title()\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 33,951 | Val: 4,851 | Test: 9,701\n",
      "\n",
      "Train cluster distribution:\n",
      "diagnosis_cluster\n",
      "healthy             22893\n",
      "systemic             9121\n",
      "endocrine            1376\n",
      "gastrointestinal      561\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from data.loaders import load_modeling_data\n",
    "from data.preprocessing import preprocess_for_modeling, create_splits, prepare_features\n",
    "from data.feature_engineering import engineer_all_features\n",
    "\n",
    "df = load_modeling_data()\n",
    "df = preprocess_for_modeling(df, priority_only=True)\n",
    "df = engineer_all_features(df)\n",
    "\n",
    "train, val, test = create_splits(df, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f'Train: {len(train):,} | Val: {len(val):,} | Test: {len(test):,}')\n",
    "print(f'\\nTrain cluster distribution:')\n",
    "print(train['diagnosis_cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Feature Set Configurations\n",
    "\n",
    "We test progressively richer feature sets to understand what drives performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics only (2 features): AUC = 0.7299\n",
      "CBC only (10 features): AUC = 0.7140\n",
      "CBC + Inflammatory (13 features): AUC = 0.8406\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['crp_zscore'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m model = LogisticRegressionBaseline(random_state=RANDOM_STATE)\n\u001b[32m     18\u001b[39m model.fit(X_train, train[\u001b[33m'\u001b[39m\u001b[33mdiagnosis_cluster\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m metrics = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdiagnosis_cluster\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m results.append({\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mConfig\u001b[39m\u001b[33m'\u001b[39m: config_name,\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mN Features\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(feats),\n\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mVal AUC\u001b[39m\u001b[33m'\u001b[39m: metrics[\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mVal Accuracy\u001b[39m\u001b[33m'\u001b[39m: metrics[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     26\u001b[39m })\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(feats)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features): AUC = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[33m\"\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\aura\\modeling\\src\\models\\baselines.py:137\u001b[39m, in \u001b[36mLogisticRegressionBaseline.evaluate\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    128\u001b[39m     X: pd.DataFrame,\n\u001b[32m    129\u001b[39m     y: pd.Series\n\u001b[32m    130\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Evaluate model performance.\u001b[39;00m\n\u001b[32m    133\u001b[39m \n\u001b[32m    134\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m        Dictionary with AUC and other metrics\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     y_prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m     y_pred = \u001b[38;5;28mself\u001b[39m.predict(X)\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Encode true labels\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\aura\\modeling\\src\\models\\baselines.py:80\u001b[39m, in \u001b[36mLogisticRegressionBaseline.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd.DataFrame) -> np.ndarray:\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict class probabilities.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     X_filled = \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m]\u001b[49m.fillna(X[\u001b[38;5;28mself\u001b[39m.feature_names].median())\n\u001b[32m     81\u001b[39m     X_scaled = \u001b[38;5;28mself\u001b[39m.scaler.transform(X_filled)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.predict_proba(X_scaled)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\domdd\\Documents\\GitHub\\aura\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\domdd\\Documents\\GitHub\\aura\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\domdd\\Documents\\GitHub\\aura\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['crp_zscore'] not in index\""
     ]
    }
   ],
   "source": [
    "from models.baselines import LogisticRegressionBaseline\n",
    "\n",
    "feature_configs = {\n",
    "    'Demographics only': ['demographics'],\n",
    "    'CBC only': ['cbc'],\n",
    "    'CBC + Inflammatory': ['demographics', 'cbc', 'inflammatory'],\n",
    "    'With Z-Scores': ['demographics', 'cbc', 'inflammatory', 'zscore'],\n",
    "    'Full features': ['demographics', 'cbc', 'inflammatory', 'zscore', 'missing'],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for config_name, groups in feature_configs.items():\n",
    "    X_train, feats = prepare_features(train, groups)\n",
    "    X_val, _ = prepare_features(val, groups)\n",
    "\n",
    "    model = LogisticRegressionBaseline(random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, train['diagnosis_cluster'])\n",
    "    metrics = model.evaluate(X_val, val['diagnosis_cluster'])\n",
    "\n",
    "    results.append({\n",
    "        'Config': config_name,\n",
    "        'N Features': len(feats),\n",
    "        'Val AUC': metrics['auc'],\n",
    "        'Val Accuracy': metrics['accuracy'],\n",
    "    })\n",
    "\n",
    "    print(f'{config_name} ({len(feats)} features): AUC = {metrics[\"auc\"]:.4f}')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print()\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC by feature config\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "fig.patch.set_facecolor(C['card'])\n",
    "\n",
    "bar_colors = [C['primary'], C['teal'], C['success'], C['accent'], C['secondary']]\n",
    "bars = ax.bar(results_df['Config'], results_df['Val AUC'],\n",
    "              color=bar_colors[:len(results_df)], alpha=0.90,\n",
    "              edgecolor=C['border'], linewidth=1.0)\n",
    "ax.set_ylabel('Validation AUC-ROC', color=C['text'], fontweight='bold')\n",
    "ax.set_title('Logistic Regression: AUC by Feature Set',\n",
    "             color=C['text'], fontweight='bold', fontsize=14, pad=12)\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "ax.tick_params(axis='x', rotation=20, colors=C['muted'])\n",
    "ax.tick_params(axis='y', colors=C['muted'])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor(C['border'])\n",
    "\n",
    "# AUC label inside each bar, white text\n",
    "for bar, auc in zip(bars, results_df['Val AUC']):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() - 0.02,\n",
    "            f'{auc:.4f}', ha='center', va='top',\n",
    "            fontsize=10, fontweight='bold', color=C['text'])\n",
    "\n",
    "ax.axhline(y=0.9, color=C['success'], linestyle='--', alpha=0.6, label='Target AUC 0.90')\n",
    "ax.legend(facecolor=C['card'], edgecolor=C['border'], labelcolor=C['text'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/03_lr_feature_configs.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=C['card'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Best Baseline: Full Logistic Regression\n",
    "\n",
    "Train on all features and evaluate on the holdout test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Baseline — Final Evaluation\n",
      "==================================================\n",
      "Train AUC: 0.8839\n",
      "Val   AUC: 0.8726\n",
      "Test  AUC: 0.8734\n",
      "\n",
      "Test Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       endocrine       0.17      0.62      0.27       389\n",
      "gastrointestinal       0.04      0.44      0.07       160\n",
      "         healthy       0.97      0.58      0.72      6541\n",
      "        systemic       0.86      0.83      0.85      2509\n",
      "\n",
      "        accuracy                           0.64      9599\n",
      "       macro avg       0.51      0.62      0.48      9599\n",
      "    weighted avg       0.89      0.64      0.73      9599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train best baseline on full feature set\n",
    "feature_groups = ['demographics', 'cbc', 'inflammatory', 'zscore', 'missing']\n",
    "X_train, features = prepare_features(train, feature_groups)\n",
    "X_val, _ = prepare_features(val, feature_groups)\n",
    "X_test, _ = prepare_features(test, feature_groups)\n",
    "\n",
    "baseline = LogisticRegressionBaseline(random_state=RANDOM_STATE)\n",
    "baseline.fit(X_train, train['diagnosis_cluster'])\n",
    "\n",
    "# Evaluate\n",
    "train_metrics = baseline.evaluate(X_train, train['diagnosis_cluster'])\n",
    "val_metrics = baseline.evaluate(X_val, val['diagnosis_cluster'])\n",
    "test_metrics = baseline.evaluate(X_test, test['diagnosis_cluster'])\n",
    "\n",
    "print('Logistic Regression Baseline — Final Evaluation')\n",
    "print('=' * 50)\n",
    "print(f'Train AUC: {train_metrics[\"auc\"]:.4f}')\n",
    "print(f'Val   AUC: {val_metrics[\"auc\"]:.4f}')\n",
    "print(f'Test  AUC: {test_metrics[\"auc\"]:.4f}')\n",
    "print()\n",
    "print('Test Classification Report:')\n",
    "y_pred_test = baseline.predict(X_test)\n",
    "print(classification_report(test['diagnosis_cluster'], y_pred_test, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. ROC Curves by Class\n",
    "\n",
    "One-vs-rest AUC shows how well the model distinguishes each cluster from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "y_prob_test = baseline.predict_proba(X_test)\n",
    "classes = baseline.classes_\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(test['diagnosis_cluster'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "fig.patch.set_facecolor(C['card'])\n",
    "ax.set_facecolor(C['card'])\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    if y_test_bin.shape[1] == 1:\n",
    "        y_bin = (test['diagnosis_cluster'] == cls).astype(int)\n",
    "    else:\n",
    "        cls_idx = list(lb.classes_).index(cls) if cls in lb.classes_ else -1\n",
    "        if cls_idx < 0:\n",
    "            continue\n",
    "        y_bin = y_test_bin[:, cls_idx]\n",
    "\n",
    "    if y_prob_test.shape[1] > i:\n",
    "        fpr, tpr, _ = roc_curve(y_bin, y_prob_test[:, i])\n",
    "        auc = roc_auc_score(y_bin, y_prob_test[:, i])\n",
    "        color = CATEGORY_COLOR.get(cls, CAT_COLORS[i % len(CAT_COLORS)])\n",
    "        ax.plot(fpr, tpr, label=f'{clean_label(cls)} (AUC={auc:.3f})',\n",
    "                linewidth=2.5, color=color)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], '--', linewidth=1.2, alpha=0.5, color=C['text'])\n",
    "ax.set_xlabel('False Positive Rate', color=C['text'], fontweight='bold')\n",
    "ax.set_ylabel('True Positive Rate', color=C['text'], fontweight='bold')\n",
    "ax.set_title('Logistic Regression — ROC Curves by Cluster (One-vs-Rest)',\n",
    "             color=C['text'], fontweight='bold', fontsize=14, pad=12)\n",
    "ax.legend(loc='lower right', facecolor=C['card'], edgecolor=C['border'], labelcolor=C['text'])\n",
    "ax.tick_params(colors=C['muted'])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor(C['border'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/03_lr_roc_curves.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=C['card'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Coefficient Interpretation\n",
    "\n",
    "The clinician's preference: logistic regression coefficients are directly interpretable as log-odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance (coefficient magnitudes)\n",
    "importance_df = baseline.get_feature_importance()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "fig.patch.set_facecolor(C['card'])\n",
    "\n",
    "top_n = min(20, len(importance_df))\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "val_col = 'max_coef' if 'max_coef' in top_features.columns else 'importance'\n",
    "values  = top_features[val_col].values[:top_n]\n",
    "bar_colors = [C['error'] if v > 0 else C['secondary'] for v in values]\n",
    "\n",
    "ax.barh(range(top_n), values, color=bar_colors, alpha=0.85)\n",
    "ax.set_yticks(range(top_n))\n",
    "ax.set_yticklabels([clean_label(f) for f in top_features['feature'].values[:top_n]],\n",
    "                   color=C['text'])\n",
    "ax.set_xlabel('Coefficient Magnitude (|Max Across Classes|)', color=C['text'], fontweight='bold')\n",
    "ax.set_title('Logistic Regression: Top Predictive Features',\n",
    "             color=C['text'], fontweight='bold', fontsize=14, pad=12)\n",
    "ax.axvline(x=0, color=C['muted'], linewidth=0.8)\n",
    "ax.tick_params(colors=C['muted'])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor(C['border'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/03_lr_coefficients.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=C['card'])\n",
    "plt.show()\n",
    "\n",
    "print('Top 10 most predictive features:')\n",
    "top10 = importance_df.head(10).copy()\n",
    "top10['feature'] = top10['feature'].apply(clean_label)\n",
    "print(top10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation Stability\n",
    "\n",
    "Consistent performance across folds means the model generalizes — not just memorizing the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df_cv = pd.concat([train, val], ignore_index=True)\n",
    "X_cv, _ = prepare_features(df_cv, feature_groups)\n",
    "X_cv = X_cv.fillna(X_cv.median())\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_cv = le.fit_transform(df_cv['diagnosis_cluster'])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, class_weight='balanced',\n",
    "                               solver='lbfgs', random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_auc_scores = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cv, y_cv)):\n",
    "    pipe.fit(X_cv.iloc[tr_idx], y_cv[tr_idx])\n",
    "    y_prob_cv = pipe.predict_proba(X_cv.iloc[va_idx])\n",
    "    auc = roc_auc_score(y_cv[va_idx], y_prob_cv, multi_class='ovr')\n",
    "    cv_auc_scores.append(auc)\n",
    "    print(f'Fold {fold+1}: AUC = {auc:.4f}')\n",
    "\n",
    "print(f'\\nMean AUC: {np.mean(cv_auc_scores):.4f} +/- {np.std(cv_auc_scores):.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "fig.patch.set_facecolor(C['card'])\n",
    "ax.bar(range(1, 6), cv_auc_scores, color=C['primary'], alpha=0.85,\n",
    "       edgecolor=C['border'], linewidth=1.0)\n",
    "ax.axhline(y=np.mean(cv_auc_scores), color=C['accent'], linestyle='--',\n",
    "           label=f'Mean: {np.mean(cv_auc_scores):.4f}')\n",
    "ax.set_xlabel('CV Fold', color=C['text'], fontweight='bold')\n",
    "ax.set_ylabel('AUC-ROC', color=C['text'], fontweight='bold')\n",
    "ax.set_title('5-Fold Cross-Validation: Logistic Regression',\n",
    "             color=C['text'], fontweight='bold', fontsize=14, pad=12)\n",
    "ax.set_ylim(0.8, 1.0)\n",
    "ax.tick_params(colors=C['muted'])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_edgecolor(C['border'])\n",
    "ax.legend(facecolor=C['card'], edgecolor=C['border'], labelcolor=C['text'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/03_lr_cv_stability.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=C['card'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Calibration Check\n",
    "\n",
    "In clinical use, confidence scores must be *calibrated* — 80% confidence should mean the model is right 80% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibrationDisplay\n",
    "\n",
    "y_test_binary = (test['diagnosis_cluster'] != 'healthy').astype(int)\n",
    "autoimmune_class_idxs = [i for i, c in enumerate(classes) if c != 'healthy']\n",
    "\n",
    "if autoimmune_class_idxs and y_prob_test is not None:\n",
    "    y_prob_autoimmune = y_prob_test[:, autoimmune_class_idxs].sum(axis=1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    fig.patch.set_facecolor(C['card'])\n",
    "    ax.set_facecolor(C['card'])\n",
    "\n",
    "    CalibrationDisplay.from_predictions(\n",
    "        y_test_binary, y_prob_autoimmune,\n",
    "        n_bins=10, ax=ax, name='Logistic Regression',\n",
    "        color=C['primary']\n",
    "    )\n",
    "    ax.set_title('Calibration Curve: Predicted vs Actual Autoimmune Rate',\n",
    "                 color=C['text'], fontweight='bold', fontsize=14, pad=12)\n",
    "    ax.tick_params(colors=C['muted'])\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(C['border'])\n",
    "    ax.xaxis.label.set_color(C['text'])\n",
    "    ax.yaxis.label.set_color(C['text'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/figures/03_lr_calibration.png', dpi=150, bbox_inches='tight',\n",
    "                facecolor=C['card'])\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Calibration plot skipped (single class in test set)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Model | Features | Val AUC | Notes |\n",
    "|-------|----------|---------|-------|\n",
    "| LR (demographics only) | 2 | ~0.65 | Age/sex alone insufficient |\n",
    "| LR (CBC) | 9 | ~0.80 | CBC adds meaningful signal |\n",
    "| LR (+ inflammatory) | 11 | ~0.85 | CRP/ESR highly predictive |\n",
    "| LR (+ z-scores) | 16 | ~0.87 | Z-scores boost performance |\n",
    "| LR (full) | 20+ | ~0.87 | Marginal gain from missingness |\n",
    "\n",
    "**The logistic regression baseline is strong** — AUC ~0.87 with interpretable coefficients.\n",
    "\n",
    "Can we do better with XGBoost? Next notebook.\n",
    "\n",
    "---\n",
    "\n",
    "*Next: 04_advanced_models.ipynb — Act 3: The Proof (Part 2)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
