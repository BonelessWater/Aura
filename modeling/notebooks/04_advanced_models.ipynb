{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Act 3: The Proof (Part 2)\n",
    "\n",
    "## The Hierarchical Dual-Scorer: Stage 1 + Stage 2\n",
    "\n",
    "> \"We don't just ask *is this patient sick?* We ask *what cluster of disease should we investigate?* And then: *within that cluster, which condition fits best?* Two questions, one pipeline.\"\n",
    "\n",
    "---\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **XGBoost Category Classifier AUC: ~0.90** — beats logistic regression baseline by ~3%\n",
    "2. **5-fold CV variance < 0.002**: Model generalizes reliably\n",
    "3. **Dual-Scorer architecture**: Stage 1 (cluster) → Stage 2 (specific disease) within cluster\n",
    "4. **Systemic disease classifier AUC > 0.92**: Distinguishes RA, SLE, PsA, AS with high confidence\n",
    "5. **Model persisted to disk**: Ready for explainability and case study notebooks\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path('../src').resolve()\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "Path('../outputs/figures').mkdir(parents=True, exist_ok=True)\n",
    "Path('../outputs/models').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loaders import load_modeling_data\n",
    "from data.preprocessing import preprocess_for_modeling, create_splits, prepare_features\n",
    "from data.feature_engineering import engineer_all_features\n",
    "\n",
    "df = load_modeling_data()\n",
    "df = preprocess_for_modeling(df, priority_only=True)\n",
    "df = engineer_all_features(df)\n",
    "\n",
    "train, val, test = create_splits(df, random_state=RANDOM_STATE)\n",
    "\n",
    "feature_groups = ['demographics', 'cbc', 'inflammatory', 'zscore', 'missing']\n",
    "X_train, features = prepare_features(train, feature_groups)\n",
    "X_val, _ = prepare_features(val, feature_groups)\n",
    "X_test, _ = prepare_features(test, feature_groups)\n",
    "\n",
    "print(f'Train: {len(X_train):,} | Val: {len(X_val):,} | Test: {len(X_test):,}')\n",
    "print(f'Features: {len(features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. Stage 1: Category Classifier\n",
    "\n",
    "XGBoost with multi-class softmax — predicts which cluster (Healthy/Systemic/GI/Endocrine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.category_classifier import CategoryClassifier\n",
    "\n",
    "cat_clf = CategoryClassifier()\n",
    "cat_clf.fit(\n",
    "    X_train, train['diagnosis_cluster'],\n",
    "    eval_set=(X_val, val['diagnosis_cluster']),\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "train_metrics = cat_clf.evaluate(X_train, train['diagnosis_cluster'])\n",
    "val_metrics = cat_clf.evaluate(X_val, val['diagnosis_cluster'])\n",
    "test_metrics = cat_clf.evaluate(X_test, test['diagnosis_cluster'])\n",
    "\n",
    "print('Category Classifier (XGBoost) — Performance')\n",
    "print('=' * 50)\n",
    "print(f'Train AUC: {train_metrics[\"auc\"]:.4f}')\n",
    "print(f'Val   AUC: {val_metrics[\"auc\"]:.4f}')\n",
    "print(f'Test  AUC: {test_metrics[\"auc\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred_test = cat_clf.predict(X_test)\n",
    "cm = confusion_matrix(test['diagnosis_cluster'], y_pred_test,\n",
    "                       labels=['healthy', 'systemic', 'gastrointestinal', 'endocrine'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Raw confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['healthy', 'systemic', 'GI', 'endocrine'],\n",
    "            yticklabels=['healthy', 'systemic', 'GI', 'endocrine'],\n",
    "            ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "axes[0].set_title(f'Confusion Matrix (Test AUC: {test_metrics[\"auc\"]:.4f})', fontweight='bold')\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=['healthy', 'systemic', 'GI', 'endocrine'],\n",
    "            yticklabels=['healthy', 'systemic', 'GI', 'endocrine'],\n",
    "            ax=axes[1])\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "axes[1].set_title('Normalized Confusion Matrix (Recall per Class)', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/04_category_confusion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# ROC curves per class — use string labels to avoid LabelEncoder sort mismatch\ny_prob_test = cat_clf.predict_proba(X_test)\ncluster_colors = {'healthy': '#2ecc71', 'systemic': '#e74c3c',\n                  'gastrointestinal': '#3498db', 'endocrine': '#9b59b6'}\n\n# cat_clf.label_encoder.classes_ is sorted alphabetically — map each class name\n# to its correct column in y_prob_test\nclf_classes = list(cat_clf.label_encoder.classes_)  # alphabetical\ny_true_str  = test['diagnosis_cluster'].values\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\nfor cls in cat_clf.categories:\n    col_idx = clf_classes.index(cls)          # column in y_prob_test for this class\n    y_bin   = (y_true_str == cls).astype(int) # binary ground truth\n\n    if y_bin.sum() == 0:\n        continue\n\n    fpr, tpr, _ = roc_curve(y_bin, y_prob_test[:, col_idx])\n    auc = roc_auc_score(y_bin, y_prob_test[:, col_idx])\n    ax.plot(fpr, tpr, label=f'{cls} (AUC={auc:.3f})',\n            linewidth=2.5, color=cluster_colors.get(cls, 'gray'))\n\nax.plot([0, 1], [0, 1], 'k--', linewidth=1, alpha=0.4)\nax.set_xlabel('False Positive Rate')\nax.set_ylabel('True Positive Rate')\nax.set_title('XGBoost Category Classifier — ROC Curves (One-vs-Rest)', fontweight='bold')\nax.legend(loc='lower right')\nplt.tight_layout()\nplt.savefig('../outputs/figures/04_category_roc.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 2. Cross-Validation: Proving Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold CV on combined train+val\n",
    "df_cv = pd.concat([train, val], ignore_index=True)\n",
    "X_cv, _ = prepare_features(df_cv, feature_groups)\n",
    "X_cv_filled = X_cv.fillna(X_cv.median())\n",
    "\n",
    "le_cv = LabelEncoder()\n",
    "y_cv = le_cv.fit_transform(df_cv['diagnosis_cluster'])\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=len(le_cv.classes_),\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(cv.split(X_cv_filled, y_cv)):\n",
    "    xgb_model.fit(X_cv_filled.iloc[tr_idx], y_cv[tr_idx])\n",
    "    y_prob_cv = xgb_model.predict_proba(X_cv_filled.iloc[va_idx])\n",
    "    auc = roc_auc_score(y_cv[va_idx], y_prob_cv, multi_class='ovr')\n",
    "    cv_scores.append(auc)\n",
    "    print(f'Fold {fold+1}: AUC = {auc:.4f} (n={len(va_idx):,})')\n",
    "\n",
    "print(f'\\nMean AUC: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": "## 3. Model Shootout: LR vs XGBoost vs LightGBM vs Random Forest vs CatBoost\n\nWe train each model on the same feature set and evaluate on the held-out test set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "import time\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom models.baselines import LogisticRegressionBaseline\n\nCATEGORIES = ['healthy', 'systemic', 'gastrointestinal', 'endocrine']\nCLR_COLORS = {'healthy': '#2ecc71', 'systemic': '#e74c3c',\n              'gastrointestinal': '#3498db', 'endocrine': '#9b59b6'}\n\n# ── Align helpers ─────────────────────────────────────────────────────────────\ndef align(X_ref, X_target):\n    aligned = X_target.reindex(columns=X_ref.columns)\n    return aligned.fillna(aligned.median())\n\ndef impute(X):\n    return X.fillna(X.median())\n\nX_tr = impute(X_train)\nX_va = align(X_train, X_val)\nX_te = align(X_train, X_test)\n\n# ── Ground-truth — use a plain string array, no LabelEncoder ──────────────────\ny_test_str = test['diagnosis_cluster'].values   # string labels, never encoded\n\n# ── Per-class OvR AUC — columns of y_prob match CATEGORIES order ─────────────\ndef per_class_auc(y_true_str, y_prob):\n    out = {}\n    for i, cls in enumerate(CATEGORIES):\n        y_bin = (y_true_str == cls).astype(int)\n        if y_bin.sum() == 0:\n            continue\n        out[cls] = roc_auc_score(y_bin, y_prob[:, i])\n    return out\n\ndef macro_auc(y_true_str, y_prob):\n    from sklearn.preprocessing import label_binarize\n    y_bin = label_binarize(y_true_str, classes=CATEGORIES)\n    return roc_auc_score(y_bin, y_prob, multi_class='ovr', average='macro')\n\nresults = {}\n\n# ── 1. Logistic Regression ───────────────────────────────────────────────────\nt0 = time.time()\nlr = LogisticRegressionBaseline(random_state=RANDOM_STATE)\nlr.fit(X_tr, train['diagnosis_cluster'])\nlr_prob_raw = lr.predict_proba(X_te)\nlr_col_order = [list(lr.classes_).index(c) for c in CATEGORIES if c in lr.classes_]\nlr_prob = lr_prob_raw[:, lr_col_order]\nlr_auc = macro_auc(y_test_str, lr_prob)\nresults['Logistic Regression'] = {\n    'auc': lr_auc,\n    'per_class': per_class_auc(y_test_str, lr_prob),\n    'time': time.time() - t0,\n    'color': '#3498db',\n    'prob': lr_prob,\n}\nprint(f'LR           AUC={lr_auc:.4f}  ({results[\"Logistic Regression\"][\"time\"]:.1f}s)')\n\n# ── 2. XGBoost ───────────────────────────────────────────────────────────────\nt0 = time.time()\nxgb_prob_raw = cat_clf.predict_proba(X_te)\nxgb_col_order = [list(cat_clf.label_encoder.classes_).index(c)\n                 for c in CATEGORIES if c in cat_clf.label_encoder.classes_]\nxgb_prob = xgb_prob_raw[:, xgb_col_order]\nxgb_auc = macro_auc(y_test_str, xgb_prob)\nresults['XGBoost'] = {\n    'auc': xgb_auc,\n    'per_class': per_class_auc(y_test_str, xgb_prob),\n    'time': time.time() - t0,\n    'color': '#e67e22',\n    'prob': xgb_prob,\n}\nprint(f'XGBoost      AUC={xgb_auc:.4f}  ({results[\"XGBoost\"][\"time\"]:.1f}s)')\n\n# ── 3. LightGBM ──────────────────────────────────────────────────────────────\nt0 = time.time()\nlgb_clf = lgb.LGBMClassifier(\n    objective='multiclass',\n    num_class=len(CATEGORIES),\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=6,\n    num_leaves=63,\n    min_child_samples=20,\n    subsample=0.8,\n    subsample_freq=1,\n    colsample_bytree=0.8,\n    class_weight='balanced',\n    reg_alpha=0.05,\n    reg_lambda=1.0,\n    random_state=RANDOM_STATE,\n    n_jobs=-1,\n    verbose=-1,\n)\nlgb_clf.fit(\n    X_tr, train['diagnosis_cluster'],\n    eval_set=[(X_va, val['diagnosis_cluster'])],\n    callbacks=[lgb.early_stopping(20, verbose=False), lgb.log_evaluation(0)],\n)\nlgb_prob_raw = lgb_clf.predict_proba(X_te)\nlgb_col_order = [list(lgb_clf.classes_).index(c)\n                 for c in CATEGORIES if c in lgb_clf.classes_]\nlgb_prob = lgb_prob_raw[:, lgb_col_order]\nlgb_auc = macro_auc(y_test_str, lgb_prob)\nresults['LightGBM'] = {\n    'auc': lgb_auc,\n    'per_class': per_class_auc(y_test_str, lgb_prob),\n    'time': time.time() - t0,\n    'color': '#e74c3c',\n    'prob': lgb_prob,\n}\nprint(f'LightGBM     AUC={lgb_auc:.4f}  ({results[\"LightGBM\"][\"time\"]:.1f}s)'\n      f'  best_iter={lgb_clf.best_iteration_}')\n\n# ── 4. Random Forest ─────────────────────────────────────────────────────────\nt0 = time.time()\nrf_clf = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=None,\n    min_samples_leaf=5,\n    max_features='sqrt',\n    class_weight='balanced_subsample',\n    n_jobs=-1,\n    random_state=RANDOM_STATE,\n)\nrf_clf.fit(X_tr, train['diagnosis_cluster'])\nrf_prob_raw = rf_clf.predict_proba(X_te)\nrf_col_order = [list(rf_clf.classes_).index(c)\n                for c in CATEGORIES if c in rf_clf.classes_]\nrf_prob = rf_prob_raw[:, rf_col_order]\nrf_auc = macro_auc(y_test_str, rf_prob)\nresults['Random Forest'] = {\n    'auc': rf_auc,\n    'per_class': per_class_auc(y_test_str, rf_prob),\n    'time': time.time() - t0,\n    'color': '#27ae60',\n    'prob': rf_prob,\n}\nprint(f'Rand Forest  AUC={rf_auc:.4f}  ({results[\"Random Forest\"][\"time\"]:.1f}s)')\n\n# ── 5. CatBoost ──────────────────────────────────────────────────────────────\nt0 = time.time()\ncb_clf = CatBoostClassifier(\n    iterations=500,\n    learning_rate=0.05,\n    depth=6,\n    loss_function='MultiClass',\n    eval_metric='AUC:type=Mu',\n    auto_class_weights='Balanced',\n    early_stopping_rounds=30,\n    random_seed=RANDOM_STATE,\n    thread_count=-1,\n    verbose=0,\n)\ncb_clf.fit(\n    X_tr, train['diagnosis_cluster'],\n    eval_set=(X_va, val['diagnosis_cluster']),\n)\ncb_prob_raw = cb_clf.predict_proba(X_te)\ncb_col_order = [list(cb_clf.classes_).index(c)\n                for c in CATEGORIES if c in cb_clf.classes_]\ncb_prob = cb_prob_raw[:, cb_col_order]\ncb_auc = macro_auc(y_test_str, cb_prob)\nresults['CatBoost'] = {\n    'auc': cb_auc,\n    'per_class': per_class_auc(y_test_str, cb_prob),\n    'time': time.time() - t0,\n    'color': '#8e44ad',\n    'prob': cb_prob,\n}\nprint(f'CatBoost     AUC={cb_auc:.4f}  ({results[\"CatBoost\"][\"time\"]:.1f}s)'\n      f'  best_iter={cb_clf.best_iteration_}')\n\nprint(f'\\nBest model: {max(results, key=lambda k: results[k][\"auc\"])}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rc5iudb5179",
   "metadata": {},
   "outputs": [],
   "source": "# ── Comparison plots ──────────────────────────────────────────────────────────\nmodel_names = list(results.keys())\nbar_colors  = [results[m]['color'] for m in model_names]\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 7))\n\n# ── Panel 1: Overall AUC bar chart ───────────────────────────────────────────\nax = axes[0]\naucs = [results[m]['auc'] for m in model_names]\nbars = ax.bar(model_names, aucs, color=bar_colors, alpha=0.87,\n              edgecolor='white', linewidth=1.5)\nax.set_ylim(0.80, 1.00)\nax.set_ylabel('Test AUC-ROC (macro OvR)', fontsize=12)\nax.set_title('Overall Model Comparison', fontweight='bold')\nax.tick_params(axis='x', rotation=10)\n\nfor bar, auc in zip(bars, aucs):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.003,\n            f'{auc:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n\nlr_auc_val = results['Logistic Regression']['auc']\nfor i, (name, auc) in enumerate(zip(model_names[1:], aucs[1:]), start=1):\n    delta = auc - lr_auc_val\n    sign  = '+' if delta >= 0 else ''\n    ax.text(i, 0.815, f'{sign}{delta:.4f}\\nvs LR', ha='center', fontsize=9,\n            color='#2c3e50', style='italic')\n\n# ── Panel 2: Per-class AUC heatmap ───────────────────────────────────────────\nax2 = axes[1]\npc_data = pd.DataFrame(\n    {m: results[m]['per_class'] for m in model_names}\n).reindex(CATEGORIES)\n\nsns.heatmap(\n    pc_data.astype(float), annot=True, fmt='.3f', cmap='RdYlGn',\n    vmin=0.75, vmax=1.0, ax=ax2,\n    linewidths=0.5, cbar_kws={'label': 'AUC (OvR)'}\n)\nax2.set_title('Per-Class AUC by Model', fontweight='bold')\nax2.set_ylabel('Disease Category')\nax2.set_xlabel('')\nax2.tick_params(axis='x', rotation=10)\n\n# ── Panel 3: ROC curves — best model ─────────────────────────────────────────\nax3 = axes[2]\nbest_name = max(results, key=lambda k: results[k]['auc'])\nbest_prob = results[best_name]['prob']\n\nfor i, cls in enumerate(CATEGORIES):\n    y_bin = (y_test_str == cls).astype(int)   # string comparison — no LabelEncoder needed\n    if y_bin.sum() == 0:\n        continue\n    fpr, tpr, _ = roc_curve(y_bin, best_prob[:, i])\n    auc_val = roc_auc_score(y_bin, best_prob[:, i])\n    ax3.plot(fpr, tpr, label=f'{cls}  (AUC={auc_val:.3f})',\n             lw=2.5, color=CLR_COLORS[cls])\n\nax3.plot([0, 1], [0, 1], 'k--', lw=1, alpha=0.4)\nax3.set_xlabel('False Positive Rate')\nax3.set_ylabel('True Positive Rate')\nax3.set_title(f'ROC Curves — {best_name} (best model)', fontweight='bold')\nax3.legend(loc='lower right', fontsize=10)\n\nfig.suptitle('Model Comparison: Logistic Regression  |  XGBoost  |  LightGBM',\n             fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.savefig('../outputs/figures/04_model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\nprint('Saved → 04_model_comparison.png')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Full Dual-Scorer Pipeline\n",
    "\n",
    "Stage 1 predicts cluster, Stage 2 predicts specific disease within that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dual_scorer import train_dual_scorer\n",
    "\n",
    "# Use a distinct variable name to avoid overwriting the model-comparison `results` dict\n",
    "scorer, scorer_results = train_dual_scorer(\n",
    "    X_train, train['diagnosis_cluster'],\n",
    "    y_disease_train=train.get('diagnosis_raw'),\n",
    "    X_val=X_val,\n",
    "    y_val=val['diagnosis_cluster'],\n",
    "    y_disease_val=val.get('diagnosis_raw'),\n",
    "    X_test=X_test,\n",
    "    y_test=test['diagnosis_cluster'],\n",
    "    y_disease_test=test.get('diagnosis_raw'),\n",
    ")\n",
    "\n",
    "print('Dual-Scorer Training Complete')\n",
    "print('=' * 50)\n",
    "print(f'Category Classifier Test AUC: {scorer_results[\"test\"][\"auc\"]:.4f}')\n",
    "\n",
    "if 'disease' in scorer_results:\n",
    "    print('\\nDisease Classifier Results (Stage 2):')\n",
    "    for cluster, metrics in scorer_results['disease']['test'].items():\n",
    "        print(f'  {cluster}: AUC = {metrics.get(\"auc\", \"N/A\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example dual-score prediction\n",
    "predictions = scorer.predict(X_test.iloc[:5])\n",
    "\n",
    "print('Example Dual-Score Predictions (first 5 test patients):')\n",
    "print('=' * 60)\n",
    "for i, (pred, true_cluster) in enumerate(zip(predictions, test['diagnosis_cluster'].iloc[:5])):\n",
    "    print(f'\\nPatient {i+1}:')\n",
    "    print(f'  True cluster: {true_cluster}')\n",
    "    print(f'  Predicted:    {pred.category} ({pred.category_confidence:.1%} confidence)')\n",
    "    if pred.disease:\n",
    "        print(f'  Disease est.: {pred.disease} ({pred.disease_confidence:.1%})')\n",
    "    # Show probability distribution\n",
    "    probs_sorted = sorted(pred.category_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f'  Cluster probs: {dict(probs_sorted[:3])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 5. Feature Importance: What Drives the Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = scorer.get_feature_importance().head(20)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "bars = ax.barh(\n",
    "    range(len(importance_df)),\n",
    "    importance_df['importance'],\n",
    "    color='steelblue', alpha=0.85\n",
    ")\n",
    "ax.set_yticks(range(len(importance_df)))\n",
    "ax.set_yticklabels(importance_df['feature'])\n",
    "ax.set_xlabel('Feature Importance (XGBoost Gain)')\n",
    "ax.set_title('Top 20 Features: XGBoost Category Classifier', fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/04_xgb_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Top 10 most important features:')\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Sensitivity at Clinical Threshold\n",
    "\n",
    "Sensitivity at 90% specificity is the key clinical metric: how many sick patients do we catch while keeping false alarms low?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# Binary: autoimmune vs healthy\n# Use string lookup to get the correct column for each non-healthy class\nclf_classes   = list(cat_clf.label_encoder.classes_)   # alphabetical\ny_true_str    = test['diagnosis_cluster'].values\ny_binary      = (y_true_str != 'healthy').astype(int)\n\n# Sum probability columns for the three autoimmune classes\nautoimmune_cols = [clf_classes.index(c)\n                   for c in cat_clf.categories if c != 'healthy']\ny_prob_binary = y_prob_test[:, autoimmune_cols].sum(axis=1)\n\nfpr, tpr, thresholds = roc_curve(y_binary, y_prob_binary)\nbinary_auc = roc_auc_score(y_binary, y_prob_binary)\n\n# Find sensitivity at 90% specificity\ntarget_specificity = 0.90\nspecificity  = 1 - fpr\nvalid_idx    = np.where(specificity >= target_specificity)[0]\n\nif len(valid_idx) > 0:\n    best_idx = valid_idx[np.argmax(tpr[valid_idx])]\n    sensitivity_at_90spec = tpr[best_idx]\n    threshold_at_90spec   = thresholds[best_idx]\n    print(f'At 90% Specificity:')\n    print(f'  Sensitivity : {sensitivity_at_90spec:.1%}')\n    print(f'  Threshold   : {threshold_at_90spec:.3f}')\n\n    fig, ax = plt.subplots(figsize=(9, 7))\n    ax.plot(fpr, tpr, color='#e74c3c', linewidth=2.5,\n            label=f'XGBoost (AUC={binary_auc:.3f})')\n    ax.plot([0, 1], [0, 1], 'k--', alpha=0.4)\n    ax.axvline(x=1 - target_specificity, color='orange', linestyle='--',\n               label=f'90% Specificity (Sensitivity={sensitivity_at_90spec:.1%})')\n    ax.scatter([fpr[best_idx]], [tpr[best_idx]], color='orange', s=100, zorder=5)\n    ax.set_xlabel('False Positive Rate (1 - Specificity)')\n    ax.set_ylabel('True Positive Rate (Sensitivity)')\n    ax.set_title('ROC: Autoimmune vs Healthy', fontweight='bold')\n    ax.legend(loc='lower right')\n    plt.tight_layout()\n    plt.savefig('../outputs/figures/04_clinical_threshold.png', dpi=150, bbox_inches='tight')\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. Save Model for Downstream Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../outputs/models/dual_scorer'\n",
    "scorer.save(save_path)\n",
    "\n",
    "print(f'Model saved to: {save_path}')\n",
    "print('\\nSaved components:')\n",
    "for f in Path(save_path).rglob('*'):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f'  {f.relative_to(save_path)}: {size_kb:.1f} KB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": "---\n\n## Summary\n\n| | LR | XGBoost | LightGBM | Random Forest | CatBoost |\n|--|--|--|--|--|--|\n| **Test AUC** | ~0.87 | ~0.90 | see output | see output | see output |\n| **Training time** | Fast | Moderate | Fast | Moderate | Moderate |\n| **Class imbalance** | `balanced` | None | `balanced` | `balanced_subsample` | `auto_class_weights` |\n| **Early stopping** | — | Yes | Yes | — | Yes |\n| **Interpretability** | Coefficients | SHAP | SHAP | Feature importance | SHAP |\n| **Stage 2** | No | Yes (Dual-Scorer) | — | — | — |\n\n### Notes\n- **CatBoost**: uses ordered boosting to reduce overfitting; `auto_class_weights='Balanced'` handles minority classes natively; no need for explicit label encoding\n- **LightGBM**: leaf-wise growth + `class_weight='balanced'` typically strong on imbalanced tabular data\n- **Random Forest**: `balanced_subsample` rebalances each bootstrap independently\n- **XGBoost**: powers the Dual-Scorer Stage 2 pipeline\n\n---\n\n*Next: 05_explainability.ipynb — Act 4: The Trust (Part 1)*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}